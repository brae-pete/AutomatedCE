{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import img_as_float32\n",
    "from scipy.signal import find_peaks\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once or if the plot doesnt appear in a new window\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Directory Location\n",
    "IMG_DIRECTORY = r\"D:\\Scripts\\MicroChip\\images\"\n",
    "SAVE_TO_DIRECTORY = \"\" \n",
    "# File save name will be the img_dir folder name\n",
    "\n",
    "# Channel parameters (in pixels)\n",
    "WIN_LEN = 10 # How long the detection window length (vertical) should be\n",
    "WALL_BUFFER = 2 # How many pixels from the wall to ignore for signal calculations\n",
    "\n",
    "# Filtering Parameters\n",
    "CUTOFF = 0.75\n",
    "ORDER = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# Adjust the angle of the detection window (INTERACTIVE)\n",
    "\"\"\"\n",
    "Left click to adjust the height of the top left side of the detection window. \n",
    "Righ click to adjust the height of the top right side of the detection window. \n",
    "\n",
    "This will get the angle we need to rotate the image by so that the channels\n",
    "are exactly straight up and down. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Get the Image files prepped in a list\n",
    "image_files = [ f for f in glob.glob(IMG_DIRECTORY+ '\\\\*.tiff')]\n",
    "\n",
    "\n",
    "total_img = []\n",
    "for i in image_files:\n",
    "    img = img_as_float32(io.imread(i))\n",
    "    if total_img ==[]:\n",
    "        total_img = img\n",
    "    else:\n",
    "        total_img += img\n",
    "\n",
    "window_length = WIN_LEN # pixels\n",
    "wall_buffer = WALL_BUFFER #  pixels\n",
    "fig, ax = plt.subplots(1)\n",
    "#ax = axes[0]\n",
    "ax.imshow(total_img)\n",
    "line1, = ax.plot((0,total_img.shape[1]), [total_img.shape[0]/2]*2)\n",
    "line2, = ax.plot((0, total_img.shape[1]), [total_img.shape[0]/2+window_length]*2)\n",
    "def onclick(event):    \n",
    "    prev_data = line1.get_ydata()\n",
    "    if event.button == 1:\n",
    "        prev_data[0]=event.ydata\n",
    "    elif event.button == 3:\n",
    "        prev_data[1]=event.ydata\n",
    "    line1.set_ydata(prev_data)\n",
    "    prev_data = np.add(prev_data, window_length)\n",
    "    line2.set_ydata(prev_data)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the Image rotation has been determined, get the Signal\n",
    "def get_zoom_region(img):\n",
    "    img = transform.rotate(img, theta, False, clip=True, preserve_range=True)\n",
    "    img[img==0]=np.nan\n",
    "    img = img[:,~np.any(np.isnan(img[int(top[0]):int(top[0])+window_length]), axis=0)]\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    \"\"\"\n",
    "    numpy = np\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError( \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError ( \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError( \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=numpy.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=numpy.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=numpy.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y[int(window_len/2-1):-int(window_len/2)]\n",
    "\n",
    "# Average all data between the two lines\n",
    "top = line1.get_ydata()\n",
    "bottom = line2.get_ydata()\n",
    "\n",
    "# Rotate the image and retrive jus the zoomed portion\n",
    "slope = (top[1]-top[0])/total_img.shape[1]\n",
    "theta = np.arcsin((top[1]-top[0])/total_img.shape[1]) \n",
    "theta = theta * 180 / np.pi\n",
    "img = get_zoom_region(total_img)\n",
    "\n",
    "# Calculate where the walls of the channel are located\n",
    "x = np.sum(img[int(top[0]):int(top[0])+window_length, :], axis=0)\n",
    "dx = np.diff(smooth(x, window='bartlett') )\n",
    "std = np.std(dx)\n",
    "\n",
    "peaks, properties = find_peaks(-dx, prominence=( std))\n",
    "peaks += 1\n",
    "properties[\"prominences\"].max()\n",
    "\n",
    "\n",
    "# Deterimine if we are odd or even (wall or channel is on the edge)\n",
    "if np.median(np.diff(peaks)[::2]) > np.median(np.diff(peaks)[1::2]):\n",
    "    start_idx = 0\n",
    "    end_idx = 1\n",
    "else:\n",
    "    start_idx = 1\n",
    "    end_idx = 2\n",
    "\n",
    "\n",
    "# Iterate through all the images and retrieve the data using the zoomed region and the wall locations\n",
    "data = []\n",
    "for img_file in image_files:\n",
    "    row = []\n",
    "    img = io.imread(img_file)\n",
    "    img = get_zoom_region(img)\n",
    "    x = np.sum(img[int(top[0]):int(top[0])+window_length, :], axis=0)\n",
    "    for start, stop in zip(peaks[start_idx::2], peaks[end_idx::2]):\n",
    "        row.append(np.sum(x[start+wall_buffer:stop-wall_buffer]))\n",
    "    data.append(row)\n",
    "    \n",
    "data = np.asarray(data)\n",
    "\n",
    "\n",
    "# Get the Time Data\n",
    "from datetime import datetime\n",
    "def get_time(file_name):\n",
    "    str_time = file_name.split('\\\\')[-1].strip('.tiff').strip('img').strip()\n",
    "    start_time = datetime.strptime(str_time, \"%y-%m-%d %H-%M-%S %f\")\n",
    "    return start_time\n",
    "\n",
    "time = []\n",
    "start_time = get_time(image_files[0])\n",
    "for image_file in image_files:\n",
    "    current_time = get_time(image_file)\n",
    "    dt = current_time-start_time\n",
    "    time.append(dt.total_seconds())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the signal data \n",
    "# Filtering Functions\n",
    "from scipy import signal\n",
    "def butter_lowpass_filter(data, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a butterworth lowpass filter to the data set.\n",
    "    Keyword arguments will be used in a dictionary of filter settings:\n",
    "    'cutoff' - frequency cutoff, should be < 1/2 the sampling frequency (fs)\n",
    "    'fs' - sampling frequncy, the frequency measurments are recorded at\n",
    "    'order' - order of the butter filter\n",
    "    'padlen' - how much to pad the beginning and end of the array (see scipy.signal.butter)\n",
    "    'padtype' - how to pad the ends of the array (see scipy.signal.butter)\n",
    "\n",
    "    :param data: 1D equally spaced array\n",
    "    :param kwargs: dict,\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    settings = {'cutoff': 3, 'fs': 10, 'order': 5, 'padlen': 24, 'padtype': 'constant'}\n",
    "    settings.update(kwargs)\n",
    "\n",
    "    b, a = butter_lowpass(settings['cutoff'], settings['fs'], order=settings['order'])\n",
    "    y = signal.filtfilt(b, a, data, padlen=settings['padlen'], padtype=settings['padtype'])\n",
    "\n",
    "    return y\n",
    "\n",
    "average_sampling_freq = 1/np.mean(np.diff(time))\n",
    "filt_data = data.copy()\n",
    "for i in range(data.shape[1]):\n",
    "    y = data[:,i]\n",
    "    filt_data[:,i] = butter_lowpass_filter(y, fs=average_sampling_freq, cutoff=0.7, order=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Summed Intensity (au)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the Fitlered Data \n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "lines = ax.plot(filt_data)\n",
    "for line in lines:\n",
    "    line.set_xdata(time)\n",
    "ax.set_xlim((0, max(time)))\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Summed Intensity (au)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as CSV files\n",
    "def out_data(fout, data, time):\n",
    "    fout.write('Time')\n",
    "    for i in range(data.shape[1]):\n",
    "        fout.write(f',Chnl_{i}')\n",
    "    fout.write('\\n')\n",
    "    for i in range(len(time)):\n",
    "        fout.write(f'{time[i]}')\n",
    "        for j in data[i,:]:\n",
    "            fout.write(f',{j}')\n",
    "        fout.write('\\n')\n",
    "        \n",
    "file_name = IMG_DIRECTORY.split('\\\\')[-1]\n",
    "with open('Raw_'+file_name+'.csv', 'w') as fout:\n",
    "    out_data(fout, data, time)\n",
    "with open('Filtered_'+file_name+'.csv', 'w') as fout:\n",
    "    out_data(fout, filt_data, time)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
